<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Chest-xray-classification : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Chest X-ray Classification</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.gatech.edu/shillerman3/chest-xray-classification">View on GitHub</a>

          <h1 id="project_title">Chest X-ray Classification</h1>
          <h2 id="project_tagline">By Steven Hillerman, Leonardo Camacho A, Wyndham Hudson, and Thomas Kim</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
          <h2>Overview</h2>
          <p>This page documents our semester project for Georgia Tech's masters level Machine Learning course in the fall of 2019.  The goal of the project was to create a program capable of taking in X-ray images of a human chest and using those images to determine if the patient has a condition called Pleural Effusion.  According to <a href = "https://medlineplus.gov/ency/article/000086.htm">MedlinePlus.gov</a>, Pleural Effusion occurs when there is an excess amount of fluid built up in the layers of tissue around the lung.  This condition can be visually identified in X-rays because the excess fluid builds up underneath one lung, causing it to be compressed vertically.  Our goal in this project was to create a program that can identify Pleural Effusion automatically using an X-ray image.</p>
          <img src="./images/pleural_effusion_diagram.svg"><br>
          Image Credit to Cancer Research UK

          <h2>Data</h2>
            <p>Our data came from a Stanford project called CheXpert.  The CheXpert project provides a large dataset of labeled X-ray images.  More information on the CheXpert project can be found <a href = "https://stanfordmlgroup.github.io/competitions/chexpert/">here</a>.
            </p>
            <p>While the dataset contained images of a variety of different medical conditions, we elected to focus on only one condition: Pleural Effusion.  We chose Pleural Effusion because there was a large number of positive cases of the condition in the dataset.  Focusing on only one condition allowed us to experiment with multiple methods of classification.  Below are example images for patients with and without Pleural Effusion.
            </p>
            <h4>No Finding:</h4>
              <img src="./images/example_no_finding.jpg"/>
            <h4>Pleural Effusion:</h4>
              <img src="./images/example_pleural_effusion.jpg"/>
            <h4>Data Details</h4>
              <p>The original dataset from CheXpert contained 223,414 images, each classified as either "No Finding" or one of several medical conditions. Because our focus was on Pleural Effusion, removed all data cases that were not either positive Pleural Effusion or positive No Finding.  This cut reduced the size of our dataset to 108,568 images.  Because Pleural Effusion can be best identified from the front, and to prevent the differences in perspective, we also removed all instances of lateral images from the dataset, focusing only on images taken from the front.  This reduced out dataset to its final size of 93,873 images.  While the original dataset contained information about each patient's age and sex, we decided to focus exclusively on the image data and labels.


          <div id="Strategy">
            <h2>Strategy</h2>
            <p>Going into the project, we were not sure what learning algorithm would be best suited for our needs.  Because of this, we decided to try several different classification algorithms and work from those results.  We tried two unsupervised algorithms: K-Means and Gaussian Mixture Model (GMM).  Neither algorithm produced very good results.  We also tried two supervised learning algorithms and one semi-supervised learning algorithm.  The first supervised learning algorithm was Convolutional Neural Networks (CNN).  The second was K-Nearest Neighbors.  Our semi-supervised learning algorithm was a version of Label Propogation called Label Spreading.  Each attempt will be documented in more detail below.
            </p>

            <div id="Algorithms">
              <h3>K-Means and Gaussian Mixture Model (GMM)</h3>
                <p>We used the sci-kit learn python packages for our implementation of K-Means and GMM.  To attempt to capture more complex data, we created 20 different clusters for each algorithm, with the intent that some clusters would be composed of mostly positive Pleural Effusion data while the rest of the clusters were mostly No Finding.  Even with 20 clusters and only the frontal images being considered, both K-Means and GMM struggled to produce any meaningful results.  Our conclusion is that unsupervised clustering is simply not powerful enough to assist in this project without significant data preprocessing to bring out the important features.
                </p>
                <p>Below are the images we reconstructed for the 20 clusters we created, as well as some plots showing the distribution of data throughout the clusters.  As you can clearly see, these approaches produced nothing of interest.</p>
                <h4>K-Means:</h4>
                  <img src="./images/kmeans_cluster_test.png"/>
                  <img src="./images/kmeans results/kmeans_20.png"/>
                <h4>GMM:</h4>
                  <img src="./images/gmm_cluster_test.png"/>
                  <img src="./images/gmm results/gmm_20.png"/>

              <h3>K-Nearest Neighbors (KNN)</h3>
                <h4>Preprocessing</h4>
                  <p> We used a preprocessing algorithm that takes the greyscale X-ray images and converts converts them to only two colors to identify areas that might be lungs. As can be seen in the image below, the lungs are significantly darker than the rest of the body, so the algorithm was able to successfully identify the lung areas to pass to our learning algorithm.  We removed any outliers leave just the lungs in the final image. This process is shown in the image below.
                  </p>
                  <img src="./images/knn_preprocess.png"/>
                <h4>Implementation</h4>
                  <p>We used the sci-kit learn implementation of the K-Nearest Neighbors algorithm. The features were extracted based on the number of pixels making up the left lung, the pixels in the right lung, and the total pixels in the image. The number of features and optimal number of neighbors was determined using the image below.
                  </p>
                  <img src="./images/knn_feat_neigh.png"/>
                <h4>Results</h4>
                  <p>The supervised KNN algorithm was a significant improvement over the unsupervised K-Means and GMM algorithms.  The maximum accuracy of the algorithm was found using 125 neighbors and two features (the ratio of left pixels to right pixels and the ratio of right pixels to total pixels).  However, at only 68.8% accuracy, we still had plenty of room for improvement in subsequent algorithms.
                  </p>
                <h4>KNN Evaluation</h4>
                  <ul>
                    <li>Accuracy Score: 0.68836</li>
                    <li>Precision Score: 0.67085</li>
                    <li>Recall Score: 0.72943</li>
                    <li>Jaccard Index: 0.53718</li>
                    <li>F1 Score (F-measure): 0.69891</li>
                  </ul>

              <h3>Label Spreading</h3>
                <h4>Preprocessing</h4>
                  <p>In this attempt, we used a different method for preprocessing our data than we used for KNN.  For Label Spreading, we read in the test images with Matplotlib's pyplot imread function.  We did not do much other preprocessing other than flattening each image to a one-dimensional numpy array.  Each pixel was considered a feature.  We used 70% of the data for training and 30% of the data for testing.
                  </p>
                <h4>Implementation</h4>
                  <p>Label Spreading is a true semi-supervised learning algorithm.  Label Spreading is a form of Label Propogation that uses a loss function and regularization to increase its capacity to handle noise.  We used the sci-kit learn implementation of the algorithm for the program.
                  </p>
                <h4>Results</h4>
                  <p>Label spreading was a significant improvement over any of the previous algorithms that we had tried.  At 86.8%, it boasted a fairly strong accuracy score, with both its Recall and F1 scores breaking 90%.  The full breakdown of evaluation scores can be seen below.
                <h4>Label Spreading Evaluation</h4>
                  <ul>
                    <li>Accuracy Score: 0.86782</li>
                    <li>Precision Score: 0.88208</li>
                    <li>Recall Score: 0.96321</li>
                    <li>Jaccard Index: 0.85333</li>
                    <li>F1 Score (F-measure): 0.92086</li>
                  </ul>

              <h3>Convolutional Neural Networks (CNN)</h3>
            </div>

          </div>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Chest-xray-classification maintained by <a href="https://github.gatech.edu/shillerman3">shillerman3</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>



  </body>
</html>
